{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "import collections\n",
    "import os\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def red_filter(img):\n",
    "    lower = np.array([0, 0, 90])\n",
    "    upper = np.array([65, 50, 255])\n",
    "    mask = cv2.inRange(img, lower, upper)\n",
    "    return mask\n",
    "\n",
    "def yellow_filter(img):\n",
    "    img = cv2.split(img)[1]\n",
    "    img = cv2.medianBlur(img,5)\n",
    "    mask = cv2.threshold(img, 110, 255, cv2.THRESH_BINARY)[1]\n",
    "    return mask\n",
    "\n",
    "def blue_filter(img):\n",
    "    lower = np.array([39, 40, 41])\n",
    "    upper = np.array([125, 140, 150])\n",
    "    mask = cv2.inRange(img, lower, upper)\n",
    "    return mask\n",
    "\n",
    "def blue_filter2(img):\n",
    "    img = cv2.split(img)[0]\n",
    "    img = cv2.medianBlur(img,5)\n",
    "    mask = np.array(cv2.threshold(img, 50, 255, cv2.THRESH_BINARY)[1])\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hexagon_contours(img):\n",
    "    img = cv2.medianBlur(img, 5)\n",
    "    bin_img = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 19, 2)\n",
    "    bin_img = cv2.medianBlur(bin_img, 5)\n",
    "    contours=cv2.findContours(bin_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "    external = cv2.findContours(bin_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "    max_ext_area =np.max([cv2.contourArea(x) for x in external])\n",
    "    areas=[]\n",
    "    for x in contours:\n",
    "        area=cv2.contourArea(x)\n",
    "        if area<max_ext_area:\n",
    "            areas.append(area)\n",
    "    max_inner_area =np.max(areas)\n",
    "    hex_list=[]\n",
    "    for x in contours:\n",
    "        area=cv2.contourArea(x)\n",
    "        if 0.5*max_inner_area<area<max_ext_area:\n",
    "            hexagon = cv2.convexHull(x)\n",
    "            epsilon = 0.05*(0.5*max_inner_area)/area * cv2.arcLength(hexagon, True)\n",
    "            hexagon = cv2.approxPolyDP(hexagon, epsilon, True)\n",
    "            if len(hexagon)==6:\n",
    "                hex_list.append(hexagon)\n",
    "    return hex_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_image(img, zoom=1.5):\n",
    "    assert(2 <= len(img.shape) <= 3)\n",
    "    \n",
    "    is_gray = len(img.shape) == 2\n",
    "    if not is_gray:\n",
    "        img = img[:,:,::-1]\n",
    "    n_len = 6.5\n",
    "    \n",
    "    n, m = img.shape[:2]\n",
    "    frac = n / float(m)\n",
    "    n, m = zoom * frac * n_len, zoom * n_len\n",
    "    \n",
    "    fig = plt.figure(figsize=(n, m))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.imshow(img, cmap='gray' if is_gray else None)\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticklabels([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(pattern=\"Group_?.bmp\"):\n",
    "    images_0 = []\n",
    "    images_1 = []\n",
    "    \n",
    "    folder = Path(\"samples\")\n",
    "    files_with_maps = folder.glob(pattern)\n",
    "    files=list(files_with_maps)\n",
    "    \n",
    "    for file in files:\n",
    "        img = cv2.imread(str(file), 0)\n",
    "        images_0.append(img)\n",
    "        \n",
    "        img = cv2.imread(str(file), 1)\n",
    "        images_1.append(img)\n",
    "        \n",
    "    return images_0, images_1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solution(folder, train, images_0, images_1, clfs = None):\n",
    "    if train:\n",
    "        fracs_red =[]\n",
    "        fracs_blue = []\n",
    "        fracs_blue2 = []\n",
    "        fracs_yellow = []    \n",
    "    for k in range(len(images_0)):\n",
    "        hex_list=hexagon_contours(images_0[k])\n",
    "        for hexagon in hex_list:\n",
    "            M = cv2.moments(hexagon)\n",
    "            cx = int(M['m10'] / M['m00'])\n",
    "            cy = int(M['m01'] / M['m00'])\n",
    "            if train is False:\n",
    "                descr = [\"\" for x in range(len(clfs))]\n",
    "            for lin in range(6):\n",
    "                red  = red_filter(images_1[k]).copy()\n",
    "                blue = blue_filter(images_1[k]).copy()\n",
    "                blue2 = blue_filter2(images_1[k]).copy()\n",
    "                yellow = yellow_filter(images_1[k]).copy()\n",
    "                x1 = hexagon[lin % 6][0][0]\n",
    "                x2 = hexagon[(lin+1)%6][0][0]\n",
    "                y2 = hexagon[(lin+1)%6][0][1]\n",
    "                y1 = hexagon[lin%6][0][1]\n",
    "                rads = math.atan2(y2 - y1, x2 - x1)\n",
    "                if rads < 0:\n",
    "                    rads = rads + 2 * math.pi\n",
    "                degs = math.degrees(rads)                \n",
    "                center = (int((x1+x2)/2),int((y1+y2)/2))\n",
    "                length = int(math.sqrt((x1-x2)**2 + (y1-y2)**2))\n",
    "                mask = np.zeros(images_0[k].shape)\n",
    "                cv2.ellipse(mask, center, (length//3, length//3), degs, 0, 180, 1, -1)\n",
    "                ellipse_area = np.sum(mask!=0)\n",
    "                red[mask==0] = 0\n",
    "                blue[mask == 0] = 0\n",
    "                blue2[mask == 0] = 0\n",
    "                yellow[mask == 0] = 0\n",
    "                area_red = np.sum(red!=0)\n",
    "                area_blue2 = np.sum(blue2!=0)\n",
    "                area_blue = np.sum(blue != 0)\n",
    "                area_yellow = np.sum(yellow!=0)\n",
    "                frac_red = round(float(area_red)/ellipse_area,2)\n",
    "                frac_blue = round(float(area_blue)/ellipse_area,2)\n",
    "                frac_blue2 = round(float(area_blue2) / ellipse_area, 2)\n",
    "                frac_yellow = round(float(area_yellow)/ellipse_area,2)\n",
    "                if train:\n",
    "                    fracs_red.append(frac_red)\n",
    "                    fracs_blue.append(frac_blue)\n",
    "                    fracs_blue2.append(frac_blue2)\n",
    "                    fracs_yellow.append(frac_yellow)\n",
    "                else:\n",
    "                    for i in range(len(clfs)):\n",
    "                        descr[i]+=str(clfs[i].predict(np.array([frac_yellow,frac_blue,frac_blue2,frac_red]).reshape(1, -1))[0])\n",
    "            if train is False:\n",
    "                for i in range(len(clfs)):\n",
    "                    s = descr[i]\n",
    "                    text = \"\"\n",
    "                    for n in range(10):\n",
    "                        if s in col_cycles_all[n]:\n",
    "                            text = str(numbers[n])\n",
    "                            break;\n",
    "                    if text != \"\":\n",
    "                        cv2.putText(images_1[k], text, (cx, cy), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2, 0)\n",
    "                        break;\n",
    "            \n",
    "        if train is False:\n",
    "            cv2.imwrite(folder+\"\\images_\"  + str(k) + \".jpg\", images_1[k])\n",
    "        else:\n",
    "            return fracs_yellow, fracs_blue, fracs_blue2, fracs_red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Обучение:\n",
    "image_0, image_1=read(\"Dozen_0.bmp\")\n",
    "fracs_yellow, fracs_blue, fracs_blue2, fracs_red=solution(\"dozen_results\",True,image_0,image_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fracs_yellow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = list(\"yybrbrrrbyybyyrbrbbyrybrrbbyyrbbryyrbbryrybryrbyrybyrbbbyryr\")\n",
    "col_cycles_all = []\n",
    "numbers = [1,2,10,9,3,5,8,6,4,7]\n",
    "for k in range(10):\n",
    "    col_cycle =[]\n",
    "    seq = np.array((ans[6*k:6*(k+1)]))\n",
    "    col_cycle.append(\"\".join(seq))\n",
    "    deq = collections.deque(seq)\n",
    "    for k in range(5):\n",
    "        deq.rotate(1)\n",
    "        col_cycle.append(\"\".join(deq))\n",
    "    col_cycles_all.append(col_cycle)\n",
    "\n",
    "import pandas as pd\n",
    "data = pd.DataFrame(ans)\n",
    "data[\"yellow\"] = fracs_yellow\n",
    "data[\"blue\"] = fracs_blue\n",
    "data[\"blue2\"] = fracs_blue2\n",
    "data[\"red\"] = fracs_red\n",
    "y = data[0]\n",
    "X = data[[\"yellow\",\"blue\",\"blue2\",\"red\"]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     y\n",
       "1     y\n",
       "2     b\n",
       "3     r\n",
       "4     b\n",
       "5     r\n",
       "6     r\n",
       "7     r\n",
       "8     b\n",
       "9     y\n",
       "10    y\n",
       "11    b\n",
       "12    y\n",
       "13    y\n",
       "14    r\n",
       "15    b\n",
       "16    r\n",
       "17    b\n",
       "18    b\n",
       "19    y\n",
       "20    r\n",
       "21    y\n",
       "22    b\n",
       "23    r\n",
       "24    r\n",
       "25    b\n",
       "26    b\n",
       "27    y\n",
       "28    y\n",
       "29    r\n",
       "30    b\n",
       "31    b\n",
       "32    r\n",
       "33    y\n",
       "34    y\n",
       "35    r\n",
       "36    b\n",
       "37    b\n",
       "38    r\n",
       "39    y\n",
       "40    r\n",
       "41    y\n",
       "42    b\n",
       "43    r\n",
       "44    y\n",
       "45    r\n",
       "46    b\n",
       "47    y\n",
       "48    r\n",
       "49    y\n",
       "50    b\n",
       "51    y\n",
       "52    r\n",
       "53    b\n",
       "54    b\n",
       "55    b\n",
       "56    y\n",
       "57    r\n",
       "58    y\n",
       "59    r\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Классификаторы\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf1 = LogisticRegression()\n",
    "clf1.fit(X,y)\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf2 = GradientBoostingClassifier()\n",
    "clf2.fit(X,y)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf3 = KNeighborsClassifier()\n",
    "clf3.fit(X,y)\n",
    "from sklearn import svm\n",
    "clf4 = svm.SVC()\n",
    "clf4.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Задача 3\n",
    "image_0, image_1=read(\"Single_?.bmp\")\n",
    "solution(\"single_results\",False,image_0,image_1,[clf1,clf2,clf3,clf4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Задача 4\n",
    "image_0, image_1=read(\"Group_?.bmp\")\n",
    "solution(\"group_results\",False,image_0,image_1,[clf1,clf2,clf3,clf4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
